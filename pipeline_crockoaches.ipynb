{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZmmdTY8Ek6u51HryuOusrY5oOawOZ9yU",
      "authorship_tag": "ABX9TyN9FZB1Csf1Ld/MCFnhpsp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marialuquin/IA-YOLO/blob/main/pipeline_crockoaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# setup parameters\n",
        "# =============================================================================\n",
        "\n",
        "epoch_=10\n",
        "batch_size_=32\n",
        "chanel=3\n",
        "img_dim=224\n",
        "batch_size_=16\n",
        "net = 'vgg16' #vgg19, resnet50, inception_v3, inception_resnet_v2, efficientnet\n",
        "# =============================================================================\n",
        "# Load  dataset Crockoaches\n",
        "# =============================================================================\n",
        "\n",
        "# Definir el directorio base donde están las carpetas de imágenes\n",
        "base_dir = '/content/drive/MyDrive/Dataset_Crockoaches/Crockoaches/train/'\n",
        "\n",
        "# Crear generadores de imágenes con aumentación de datos\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,          # Rotación de hasta 40 grados\n",
        "    width_shift_range=0.2,      # Desplazamiento horizontal de hasta el 20%\n",
        "    height_shift_range=0.2,     # Desplazamiento vertical de hasta el 20%\n",
        "    shear_range=0.2,            # Transformación de corte\n",
        "    zoom_range=0.2,             # Zoom de hasta el 20%\n",
        "    horizontal_flip=True,       # Inversión horizontal\n",
        "    fill_mode='nearest',        # Estrategia de llenado de nuevos píxeles\n",
        "    brightness_range=[0.8, 1.2],# Variación en el brillo de 80% a 120%\n",
        "    validation_split=0.2)       # 20% de los datos para validación\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Cargar las imágenes y separarlas en entrenamiento y validación\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_dim, img_dim),  # Ajusta el tamaño de las imágenes según sea necesario\n",
        "    batch_size=batch_size_,\n",
        "    class_mode='categorical',\n",
        "    subset='training')  # Conjunto de entrenamiento\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=batch_size_,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')  # Conjunto de validación\n",
        "\n",
        "# Crear un generador para el conjunto de prueba\n",
        "# Asumiendo que tienes un directorio separado para el conjunto de prueba\n",
        "test_dir = '/content/drive/MyDrive/Dataset_Crockoaches/Crockoaches/test/'\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=batch_size_,\n",
        "    class_mode='categorical')\n",
        "\n",
        "print('Classes:', train_generator.class_indices)\n",
        "print('Training samples:', train_generator.samples)\n",
        "print('Validation samples:', validation_generator.samples)\n",
        "print('Testing samples:', test_generator.samples)\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "nb_class = len(labels)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Fine-Tuning\n",
        "# =============================================================================\n",
        "# Cargar el modelo base VGG16 sin las capas superiores\n",
        "if net == 'vgg16':\n",
        "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "if net == 'vgg19':\n",
        "  base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "if net == 'resnet50':\n",
        "  base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "if net == 'inception_v3':\n",
        "  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "if net == 'inception_resnet_v2':\n",
        "  base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "if net == 'efficientnet':\n",
        "  base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_dim, img_dim, chanel))\n",
        "\n",
        "# Congelar las capas del modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Añadir nuestras propias capas superiores\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(nb_class, activation='softmax')  # Capa final con 4 neuronas y activación softmax\n",
        "])\n",
        "\n",
        "# =============================================================================\n",
        "# Metrics evaluation\n",
        "# =============================================================================\n",
        "metrics_ = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\")\n",
        "]\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[metrics_, 'accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Dataset_Crockoaches/Modelos/'+net+'_best_model.h5',\n",
        "                              verbose=1,\n",
        "                              monitor='val_loss',\n",
        "                              save_best_only=True,\n",
        "                              mode='min')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   mode='min',\n",
        "                                   baseline=None,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "\n",
        "history_model = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=epoch_,\n",
        "    callbacks=[es, checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Cargar el mejor modelo guardado\n",
        "model.load_weights('/content/drive/MyDrive/Dataset_Crockoaches/Modelos/'+net+'_best_model.h5')\n",
        "\n",
        "model.save('/content/drive/MyDrive/Dataset_Crockoaches/Modelos/'+net+'_modelo_finetuned.h5')\n",
        "\n",
        "\n",
        "plt.plot(history_model.history['precision'])\n",
        "plt.plot(history_model.history['val_precision'])\n",
        "plt.title('Model precision')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('/content/drive/MyDrive/Dataset_Crockoaches/Plots/'+net+'_Precision.png')\n",
        "plt.clf()\n",
        "\n",
        "# Plot training & validation loss values.\n",
        "plt.plot(history_model.history['accuracy'])\n",
        "plt.plot(history_model.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('/content/drive/MyDrive/Dataset_Crockoaches/Plots/'+net+'_accuracy.png')\n",
        "plt.clf()\n",
        "\n",
        "# Evaluar el modelo en el conjunto de validación\n",
        "evaluation = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Guardar los resultados en un archivo de texto\n",
        "with open('/content/drive/MyDrive/Dataset_Crockoaches/Resultados/'+net+'_resultados_evaluacion.txt', 'w') as f:\n",
        "    f.write(f'Pérdida de validación: {evaluation[0]}\\n')\n",
        "    f.write(f'Exactitud de validación: {evaluation[1]}\\n')\n",
        "\n",
        "print(f'Pérdida de validación: {evaluation[0]}')\n",
        "print(f'Exactitud de validación: {evaluation[1]}')\n",
        "\n",
        "# Obtener las predicciones del modelo\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "\n",
        "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_generator.classes[:len(y_pred)]\n",
        "\n",
        "# Calcular la exactitud de las predicciones\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(accuracy)\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualizar la matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('/content/drive/MyDrive/Dataset_Crockoaches/Plots/'+net+'_matriz_de_confusion.png')\n",
        "plt.show()\n",
        "\n",
        "# Guardar la matriz de confusión en un archivo de texto\n",
        "np.savetxt('/content/drive/MyDrive/Dataset_Crockoaches/Resultados/'+net+'_matriz_de_confusion.txt', cm, fmt='%d')\n",
        "\n",
        "# Reporte de clasificación\n",
        "report = classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys())\n",
        "print(report)\n",
        "\n",
        "# Guardar el reporte de clasificación en un archivo de texto\n",
        "with open('/content/drive/MyDrive/Dataset_Crockoaches/Resultados/'+net+'_reporte_clasificacion.txt', 'w') as f:\n",
        "    f.write(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEWKxXX_yQOP",
        "outputId": "83a21ec6-8c5b-412a-a4f6-9895d3bea5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Found 733 images belonging to 4 classes.\n",
            "Found 182 images belonging to 4 classes.\n",
            "Found 230 images belonging to 4 classes.\n",
            "Classes: {'Especie1': 0, 'Especie2': 1, 'Especie3': 2, 'Especie4': 3}\n",
            "Training samples: 733\n",
            "Validation samples: 182\n",
            "Testing samples: 230\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-511b504439bf>:155: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history_model = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.9310 - fn: 309.0000 - tn: 1913.0000 - tp: 408.0000 - precision: 0.6316 - recall: 0.5690 - accuracy: 0.5997\n",
            "Epoch 1: val_loss improved from inf to 0.33163, saving model to /content/drive/MyDrive/Dataset_Crockoaches/Modelos/vgg16_best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/45 [==============================] - 299s 6s/step - loss: 1.9310 - fn: 309.0000 - tn: 1913.0000 - tp: 408.0000 - precision: 0.6316 - recall: 0.5690 - accuracy: 0.5997 - val_loss: 0.3316 - val_fn: 23.0000 - val_tn: 521.0000 - val_tp: 153.0000 - val_precision: 0.9563 - val_recall: 0.8693 - val_accuracy: 0.9205\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2767 - fn: 84.0000 - tn: 2099.0000 - tp: 633.0000 - precision: 0.9241 - recall: 0.8828 - accuracy: 0.9066\n",
            "Epoch 2: val_loss improved from 0.33163 to 0.22209, saving model to /content/drive/MyDrive/Dataset_Crockoaches/Modelos/vgg16_best_model.h5\n",
            "45/45 [==============================] - 24s 531ms/step - loss: 0.2767 - fn: 84.0000 - tn: 2099.0000 - tp: 633.0000 - precision: 0.9241 - recall: 0.8828 - accuracy: 0.9066 - val_loss: 0.2221 - val_fn: 12.0000 - val_tn: 520.0000 - val_tp: 164.0000 - val_precision: 0.9535 - val_recall: 0.9318 - val_accuracy: 0.9318\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1885 - fn: 52.0000 - tn: 2116.0000 - tp: 665.0000 - precision: 0.9500 - recall: 0.9275 - accuracy: 0.9414\n",
            "Epoch 3: val_loss improved from 0.22209 to 0.15510, saving model to /content/drive/MyDrive/Dataset_Crockoaches/Modelos/vgg16_best_model.h5\n",
            "45/45 [==============================] - 24s 526ms/step - loss: 0.1885 - fn: 52.0000 - tn: 2116.0000 - tp: 665.0000 - precision: 0.9500 - recall: 0.9275 - accuracy: 0.9414 - val_loss: 0.1551 - val_fn: 10.0000 - val_tn: 523.0000 - val_tp: 166.0000 - val_precision: 0.9708 - val_recall: 0.9432 - val_accuracy: 0.9489\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1629 - fn: 40.0000 - tn: 2120.0000 - tp: 677.0000 - precision: 0.9562 - recall: 0.9442 - accuracy: 0.9554\n",
            "Epoch 4: val_loss improved from 0.15510 to 0.09726, saving model to /content/drive/MyDrive/Dataset_Crockoaches/Modelos/vgg16_best_model.h5\n",
            "45/45 [==============================] - 22s 481ms/step - loss: 0.1629 - fn: 40.0000 - tn: 2120.0000 - tp: 677.0000 - precision: 0.9562 - recall: 0.9442 - accuracy: 0.9554 - val_loss: 0.0973 - val_fn: 8.0000 - val_tn: 521.0000 - val_tp: 168.0000 - val_precision: 0.9600 - val_recall: 0.9545 - val_accuracy: 0.9545\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1432 - fn: 47.0000 - tn: 2116.0000 - tp: 670.0000 - precision: 0.9504 - recall: 0.9344 - accuracy: 0.9414\n",
            "Epoch 5: val_loss did not improve from 0.09726\n",
            "45/45 [==============================] - 21s 473ms/step - loss: 0.1432 - fn: 47.0000 - tn: 2116.0000 - tp: 670.0000 - precision: 0.9504 - recall: 0.9344 - accuracy: 0.9414 - val_loss: 0.1284 - val_fn: 11.0000 - val_tn: 521.0000 - val_tp: 165.0000 - val_precision: 0.9593 - val_recall: 0.9375 - val_accuracy: 0.9545\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0931 - fn: 24.0000 - tn: 2134.0000 - tp: 693.0000 - precision: 0.9761 - recall: 0.9665 - accuracy: 0.9707\n",
            "Epoch 6: val_loss improved from 0.09726 to 0.09374, saving model to /content/drive/MyDrive/Dataset_Crockoaches/Modelos/vgg16_best_model.h5\n",
            "45/45 [==============================] - 21s 477ms/step - loss: 0.0931 - fn: 24.0000 - tn: 2134.0000 - tp: 693.0000 - precision: 0.9761 - recall: 0.9665 - accuracy: 0.9707 - val_loss: 0.0937 - val_fn: 4.0000 - val_tn: 525.0000 - val_tp: 172.0000 - val_precision: 0.9829 - val_recall: 0.9773 - val_accuracy: 0.9773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pizbemFlzXxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}